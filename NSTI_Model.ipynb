{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NSTI_Model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9j0RvBIZDRrF"},"source":["# NSTI Modeling preset "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AaklX6wqHWkB","colab":{}},"source":["import numpy as np\n","import pandas as pd # data import and maniplation \n","import os \n","import seaborn as sns # data visualization \n","import matplotlib.pyplot as plt # data visualization \n","import re\n","from datetime import datetime, timedelta\n","\n","from sklearn import datasets, linear_model # regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split # data split "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v58D08elDRrI"},"source":["# Input data\n","\n","Input: 4 filess \n","\n","Output: 4 dataframes that are stripped "]},{"cell_type":"code","metadata":{"id":"cGh0ZlwsGWAo","colab_type":"code","colab":{}},"source":["# if I want to change between google collab or spyder \n","if False:\n","    from google.colab import files\n","    files.upload()    \n","nsti_med = pd.read_csv(\"NSTI_meds_for_KL.csv\", na_values = [\"NA\"])\n","nsti_debride = pd.read_csv(\"NSTI_debride_for_KL.csv\", na_values = [\"NA\"])\n","nsti = pd.read_csv(\"NSTI_for_KL.csv\", na_values = [\"NA\"])\n","nsti_wbc = pd.read_csv(\"NSTI_WBC_updated_for_KL.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"libBeF-FEkHj","colab":{}},"source":["#issues with extra white spaces \n","nsti_med.columns = nsti_med.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n","nsti_debride.columns = nsti_debride.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n","nsti.columns = nsti.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n","nsti_wbc.columns = nsti_wbc.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n","\n","#issues with extra white spaces \n","nsti_medt = nsti_med.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n","nsti_debridet = nsti_debride.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n","nstit = nsti.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n","nsti_wbct = nsti_wbc.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E3VyA5x0DRrL"},"source":["## Shape of the datasets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sd58sVZGE-mm","outputId":"c22c62c2-dd8e-4a6f-a5b0-10943880d2b9","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print(nsti_medt.shape)\n","print(nsti_debridet.shape)\n","print(nstit.shape)\n","print(nsti_wbct.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(35410, 6)\n","(502, 80)\n","(432, 78)\n","(9730, 7)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DkZEC01AcPZ4"},"source":["# NSTI clean up / merge "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"98XJn0NIHLOy","colab":{}},"source":["#removes the suffix in the nsti dataset for easier merging \n","nstit['patient'] = pd.to_numeric(nstit['patient'].str.split(\"*\", n = 1, expand = True)[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EbGmAqbtjWXb"},"source":["# [NSTI med]Data manipulation\n"]},{"cell_type":"markdown","metadata":{"id":"1pR-VqlSGBCd","colab_type":"text"},"source":["## [NSTI med] cleanup \n","\n","Removes NA's + other clean up"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FL_zSzqQjt19","colab":{}},"source":["# removes bad entries \n","nsti_medt = nsti_medt[(nsti_medt[\"med_start_date\"] != \"NOT\") & \n","                      (nsti_medt[\"med_start_date\"] != \"\")  & \n","                      (nsti_medt[\"med_start_date\"] != \"UNK\") & \n","                      (nsti_medt[\"med_start_date\"] != \"NA\")]\n","\n","# removes antibiotics that aren't needed\n","nsti_medt = nsti_medt[~  nsti_medt['meds'].isin([\"DOBU\", \"ENOX\", \"EPINEP\", \"NOPRESS\", \"STERIOD\", \"VASO\", \"WARF\", \n","                                                 \"ANTIBIOT\", \"DOP\", \"HEP\", \"IVIG\", \"NOREPI\", \"PCC\", \"SOFA\"])]\n","\n","#removes stuff from time date \n","nsti_medt[\"med_start_time\"] = nsti_medt[\"med_start_time\"].apply(lambda x: x.replace(\"NOT\", \"0:00\")).apply(lambda x: x.replace(\"UNK\", \"0:00\")).apply(lambda x: x.replace(\"NA\", \"0:00\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1b-FUvwwDRre"},"source":["## [NSTI med][NSTI wbc]  Data Manipulation\n","\n","Combining date and time and converting it to time date format\n","\n","Also converting the time of wbc for validation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N48n-m74_oXr","colab":{}},"source":["# combines into a full date and formats the string type\n","nsti_medt['total_time'] = nsti_medt['med_start_date'] + \" \" + nsti_medt['med_start_time']\n","nsti_medt['total_time'] = pd.to_datetime(nsti_medt['total_time'].apply(lambda x: x.strip(\" \")), format = '%m/%d/%Y %H:%M')\n","\n","#remove the parent columns \n","nsti_medt = nsti_medt[nsti_medt.columns[~nsti_medt.columns.str.contains('med_start')]]\n","\n","# Formating the times to time data\n","nsti_wbct['observationdttm'] = pd.to_datetime(nsti_wbct['observationdttm'].apply(lambda x: x.strip(\" \")), format = '%m/%d/%y %H:%M')\n","nsti_wbct['specimenreceiveddttm'] = pd.to_datetime(nsti_wbct['specimenreceiveddttm'].apply(lambda x: x.strip(\" \")), format = '%m/%d/%y %H:%M')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h1-bNrquGBCk","colab_type":"text"},"source":["## [NSTI_medt][NSTI_wbct] Date validation\n","ASK: Match the last WBC date to the last date in the medication\n","\n","\n","Notes: Outputed a csv towards comparing the different latest times in the medication and wbc files \n"]},{"cell_type":"code","metadata":{"id":"cZdir_XbGBCl","colab_type":"code","colab":{}},"source":["# Takes medt and wbct df, abstracts identifer and time, takes only the most recent date of each patient \n","testmedt = nsti_medt.sort_values(by = ['study_id','total_time'], ascending = [True, False]).drop_duplicates(subset = ['study_id'], keep = 'first')\n","#testwbct = nsti_wbct.sort_values(by = ['patient', 'observationdttm'], ascending = [True, False]).drop_duplicates(subset = ['patient'], keep = 'first')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"alpFBtJIGBCn","colab_type":"code","colab":{},"outputId":"f8826c5e-027e-4740-f4ff-90fea2705717"},"source":["test = nsti_wbct.merge(testmedt[['study_id', 'total_time']], how = 'left', left_on = 'patient', right_on = 'study_id')\n","test['difference'] = abs(test['observationdttm'] - test['total_time'])\n","test.sort_values(by = ['patient', 'difference'], ascending = [True, True]).drop_duplicates(subset = ['patient'], keep = 'first')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>study_id</th>\n","      <th>admit_date</th>\n","      <th>meds</th>\n","      <th>med_location</th>\n","      <th>total_time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13791</th>\n","      <td>1</td>\n","      <td>3/18/2015</td>\n","      <td>MERO</td>\n","      <td>NA</td>\n","      <td>2015-04-22 09:33:00</td>\n","    </tr>\n","    <tr>\n","      <th>13757</th>\n","      <td>1</td>\n","      <td>3/18/2015</td>\n","      <td>MERO</td>\n","      <td>NA</td>\n","      <td>2015-04-22 00:46:00</td>\n","    </tr>\n","    <tr>\n","      <th>13801</th>\n","      <td>1</td>\n","      <td>3/18/2015</td>\n","      <td>MERO</td>\n","      <td>NA</td>\n","      <td>2015-04-21 16:40:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       study_id admit_date  meds med_location          total_time\n","13791         1  3/18/2015  MERO           NA 2015-04-22 09:33:00\n","13757         1  3/18/2015  MERO           NA 2015-04-22 00:46:00\n","13801         1  3/18/2015  MERO           NA 2015-04-21 16:40:00"]},"metadata":{"tags":[]},"execution_count":224}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TAAIXIqUDRrh"},"source":["## Creating a proxy dataset for just total time andy study id"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZgAoLRA4XF8o","colab":{}},"source":["# makes it so there isn't any duplicate \n","nsti_med_max = nsti_medt[['study_id', 'total_time']]\n","nsti_med_max = nsti_med_max.drop_duplicates(subset = ['study_id', 'total_time'], keep = 'first')\n","idx = nsti_med_max.groupby(['study_id'])['total_time'].transform(max) == nsti_med_max['total_time']\n","       \n","nsti_med_max = nsti_med_max[idx]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OK_TFY1AGBCu","colab_type":"text"},"source":["# [nstit][nsti_debridet] Merger of nsti demo and debride data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vETJeDBtLTiE","colab":{}},"source":["# Merges the debride and nsti df to one \n","nsti_full = nstit.merge(nsti_debridet, left_on= \"patient\", right_on = \"study_id\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tHOtZ2axDRro"},"source":["## Removing featuresfrom nsti_full\n","\n","Removes Cost, deb, and rec data from the overall dataset while keeping it as a seperate dataset with identifiers \n","\n","- debisolate\n","- recisolate "]},{"cell_type":"code","metadata":{"id":"m2_w5O6XGBCz","colab_type":"code","colab":{}},"source":["#Remove cost data\n","listcost = list(i for i in list(nsti_full.columns) if not (re.search(r'(costs)',i)))\n","nsti_full = nsti_full[listcost]\n","\n","# removing the deb data \n","listdeb = list(i for i in list(nsti_full.columns) if (re.search(r'^(deb)',i)))\n","debisolate = nsti_full[['patient']+listdeb]\n","nsti_full.drop(listdeb, axis = 1, inplace = True)\n","\n","# removin the rec data\n","listrec = list(i for i in list(nsti_full.columns) if (re.search(r'^(rec)',i)))\n","recisolate = nsti_full[['patient']+listrec]\n","nsti_full.drop(listrec, axis = 1, inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K_KYclMuDRrj"},"source":["## Formatting the date in [nsti_full] and pulling the target variable"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CP8LP7imkm9Z","colab":{}},"source":["# Removing nulls\n","nsti_full = nsti_full[nsti_full['minutes_from'] != \"NA\"]\n","\n","#Formating string dates to timedate type\n","nsti_full['admit.x'] = pd.to_datetime(nsti_full['admit.x'], format = '%m/%d/%Y')\n","nsti_full['discharge'] = pd.to_datetime(nsti_full['discharge'], format = '%m/%d/%Y')\n","nsti_full['minutes_from'] = pd.to_numeric(nsti_full['minutes_from']).apply(lambda x: timedelta(minutes = x))\n","\n","# Making a feature that combines the minutes from {admit to last debridement} \n","# and the date of the admission to get rough time of the actual time date of debridement\n","nsti_full['admittodeb'] = nsti_full['admit.x'] + nsti_full['minutes_from']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJS4adWTGBC5","colab_type":"text"},"source":["## TASK: Find the difference in time between the last debridement and last medication \n","\n","- Status: Completed \n","\n","- Notes: \n","\n","The main issue is that there are negative values when it should be mostly positive.\n","\n","It was noted that for some of the patients, incomplete data as well as wrong indication towards data usage.\n","\n","Manual picking is needed \n","\n","- Updates: Need to work off of the new dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4RfDrMq2npKV","colab":{}},"source":["# making sure that the dataset only has positive variables \n","nsti_complete = nsti_full.merge(nsti_med_max, left_on = 'patient', right_on= 'study_id' )\n","\n","# Creating a new feature in the difference in hours \n","nsti_complete['debtomed'] = (nsti_complete['total_time'] - nsti_complete['admittodeb']) / np.timedelta64(1, 'h') \n","nsti_complete = nsti_complete.loc[nsti_complete['debtomed'] >= 0.0]\n","nsti_complete = nsti_complete[nsti_complete.columns[~nsti_complete.columns.str.contains('minutes')]]\n","\n","# Cleaning up the dataset by eliminating some of the extra features \n","nsti_complete.drop(['discharge','sex','admit.x','location.code.1', 'location.code.2','icd.10.code..1', 'icd.10..1.description','icd.10.code..2','icd10..2.descrition','admit.y',\n","                    'insure','insure_type','admit_date','dc_date','transfer_y','dc.dispo','admittodeb', 'total_time','study_id_y','study_id_x','transfer_x'], axis = 1, inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPg8qbksGBC8","colab_type":"text"},"source":["# Model creation \n","\n","Under construction need some more work and understand of the data "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YTQLrnpbzDFX"},"source":["# Feature encoding \n","\n","Need to figure out what exactly to encode some of the features "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N5rUDoiYDRr5","outputId":"56cb7130-037d-4fdd-cabf-57e920d1e247","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["nsti_complete_filter = nsti_complete[nsti_complete['debtomed'] <5000]\n","\n","binary_change = {\"outcome\": {\"A\": 1, \"D\": 0}}\n","\n","nsti_complete_filter.replace(binary_change, inplace=True)\n","nsti_complete_filter.head()\n","\n","#https://stackoverflow.com/questions/29034928/pandas-convert-a-column-of-list-to-dummies\n","nsti_complete_filter = pd.get_dummies(nsti_complete_filter, columns =['mechanism.of.infection', 'race'])\n","\n","dummy_code = pd.get_dummies(nsti_complete_filter['comorbid.codes'].str.split(';').apply(pd.Series).stack()).sum(level=0)\n","dummy_region = pd.get_dummies(nsti_complete_filter['region'].str.split('; ').apply(pd.Series).stack()).sum(level=0)\n","df_dummyfull = pd.concat([dummy_code,dummy_region],axis=1,join = 'inner')\n","nsti_new = pd.concat([nsti_complete_filter, dummy_region], axis = 1)\n","nsti_new.drop(['region','patient','comorbid.codes','co.morbids','icu.los','icu.hours','hosp.los', 'vent.days'], axis = 1, inplace = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6517: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  regex=regex)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"biganBcpDRr2"},"source":["Converting to all floats "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kWPS2MFF_YAt","scrolled":true,"colab":{}},"source":["# see how many na are there\n","fig, ax = plt.subplots(figsize=(15,10))\n","sns.heatmap(nsti_new.dropna().isnull(), cbar=False, cmap=\"YlGnBu_r\")\n","fig.patch.set_facecolor('xkcd:mint green')\n","plt.show()\n","\n","#nsti_new.dropna(axis=1,how='all')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g6x4tZtfI4aA","colab":{}},"source":["corr = nsti_new.corr()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-IaWBlRXSAXf","colab":{}},"source":["fig, ax = plt.subplots(figsize=(20,14))\n","sns.heatmap(corr, \n","        xticklabels=corr.columns,\n","        yticklabels=corr.columns,\n","        cmap = \"PiYG\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Htp9ujwy1z8t"},"source":["Doesn't seem to be that much correlation for our target "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CqVFFymFDRsS"},"source":["Feature selection"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9JDW3yGdDRsS","colab":{}},"source":["from sklearn.feature_selection import RFE\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","import seaborn as sns\n","import statsmodels.api as sm\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ohZwPrHIqGmB","outputId":"f2ff0189-c4e6-48f5-ad34-a9be77ee1a22","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","nsti_new = nsti_new.dropna()\n","y = nsti_new['debtomed']\n","y = y.astype('int')\n","nsti_new.drop(['debtomed','unnamed:_0'], axis = 1, inplace = True)\n","X = nsti_new\n","\n","# Univariate selection\n","bestfeatures = SelectKBest(score_func=chi2, k=10)\n","fit = bestfeatures.fit(X,y)\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(X.columns)\n","#concat two dataframes for better visualization \n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n","print(featureScores.nlargest(10,'Score'))  #print 10 best features\n","\n","#tasks: Need to convert other strings to numerical or numeraid"],"execution_count":0,"outputs":[{"output_type":"stream","text":["                          Specs       Score\n","0                           age  961.014047\n","54                        race_  368.000000\n","48  mechanism.of.infection_BURN  368.000000\n","6                         cauti  368.000000\n","18                          vap  368.000000\n","20                     bleeding  368.000000\n","15                           pe  322.000000\n","13                unplanned.ett  312.166667\n","16                 unplanned.or  304.500000\n","10                          cpr  291.250000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dwErsLFRnWtz","outputId":"a7be853e-badc-4c51-d2b8-a112b69b9758","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model = LinearRegression().fit(X[['age','race_','mechanism.of.infection_BURN', 'cauti','vap','bleeding','pe','unplanned.ett','unplanned.or','cpr']], y)\n","\n","r_sq = model.score(X[['age','race_','mechanism.of.infection_BURN', 'cauti','vap','bleeding','pe','unplanned.ett','unplanned.or','cpr']], y)\n","print('coefficient of determination:', r_sq)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["coefficient of determination: 0.04367364652493122\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P07ZPzEUEj0L"},"source":["Seeing as a linear regression doesn't really help with this"]}]}