{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zC9fYnZBNsxB"
   },
   "source": [
    "Workflow:\n",
    "1. Question or problem definition.\n",
    "2. Acquire training and testing data.\n",
    "3. Wrangle, prepare, cleanse the data.\n",
    "4. Analyze, identify patterns, and explore the data.\n",
    "5. Model, predict and solve the problem.\n",
    "6. Visualize, report, and present the problem solving steps and final solution.\n",
    "7. Supply or submit the results.\n",
    "\n",
    "At each step have questions that you might have \n",
    "Make assumptions at the end or generate assumptions that lead to it \n",
    "The make decisions after some visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqzxzXYEWsOK"
   },
   "source": [
    "# Correlation between different data types \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HMy_v3pXgeh"
   },
   "source": [
    "##categorical vs continuous\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svr5ViVeX19T"
   },
   "source": [
    "###Point biserial correlation\n",
    "\n",
    "\n",
    "\n",
    "- Special case of the pearsone correlation coefficent \n",
    "- Ranges from -1 to 1 \n",
    "- assumes that the continuous variable is normally distributed and homoscedastic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dpn-FsoaXOX4"
   },
   "outputs": [],
   "source": [
    "<a id = 'test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BgJVnmbX3pY"
   },
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PyJX9CxhX6IN"
   },
   "source": [
    "### Kruskal Wallis H Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDDW2C3Xe2-N"
   },
   "outputs": [],
   "source": [
    "pd.cut # cuts a set by bins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YwPAyLP7pzD"
   },
   "source": [
    "Lambda operations **important for small one time functions that apply **\n",
    "\n",
    "lambda arguments : expression\n",
    "\n",
    "Basically it allows for one to alter the arguments to make some expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nMAXALF7ouG"
   },
   "outputs": [],
   "source": [
    "# Can be used in conjugtion with a map \n",
    "def multiply2(x):\n",
    "  return x * 2\n",
    "    \n",
    "map(multiply2, [1, 2, 3, 4])\n",
    "# = \n",
    "\n",
    "map(lambda x : x*2, [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ku5xBstPN8eW"
   },
   "source": [
    "# Acquiring Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOBebGxDsa6I"
   },
   "outputs": [],
   "source": [
    "# Import Data:\n",
    "\n",
    "pd.read_csv()\n",
    "\n",
    "# Check a small amount of rows \n",
    "xxxx.head(#)  \n",
    "\n",
    "# NA Detection\n",
    "- .is.null().sum()\n",
    "- .notnull()\n",
    "    \n",
    "# You can make heatmaps for NA \n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "sns.heatmap(df_train.isnull(), cbar=False, cmap=\"YlGnBu_r\")\n",
    "plt.show()\n",
    "\n",
    "#change the background axes background color with https://stackoverflow.com/questions/14088687/how-to-change-plot-background-color\n",
    "fig.patch.set_facecolor('xkcd:mint green')\n",
    "    \n",
    "# Fill in NA\n",
    "combined.Embarked.fillna('S', inplace=True)  # Dataset.columnname.fillna\n",
    "    \n",
    "# combining both train and test in the same dataset allows them to be jointly edited on\n",
    "# better\n",
    "combined = train.append(test)\n",
    "combined.reset_index(inplace=True)\n",
    "# or \n",
    "combine = [xxx,yyyy] \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMahDVnI44bm"
   },
   "source": [
    "Filling in NA \n",
    "- For something like contiguous try to group a dataset on a few preexisting features then use a metric like median to set standarized age groups, then run through all of the dataset to check if it is na and then from there  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BT03Li-g4wip"
   },
   "outputs": [],
   "source": [
    "#Filling in NA with something that is numerical like Age\n",
    "#EX \n",
    "grouped_train = combined.iloc[:891].groupby(['Sex','Pclass'])\n",
    "grouped_median_train = grouped_train.median()\n",
    "grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Age']]\n",
    "\n",
    "def fill_age(row):\n",
    "    condition = (\n",
    "        (grouped_median_train['Sex'] == row['Sex']) & \n",
    "        (grouped_median_train['Title'] == row['Title']) & \n",
    "        (grouped_median_train['Pclass'] == row['Pclass'])\n",
    "    ) \n",
    "    return grouped_median_train[condition]['Age'].values[0]\n",
    "  \n",
    "# you can easily test the if statements and that of multiple features with '()' and & \n",
    "# works in the way that all the different combinations work just that there\n",
    "  \n",
    "  \n",
    "def process_age():\n",
    "    global combined\n",
    "    # a function that fills the missing values of the Age variable\n",
    "    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    status('age')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbTi_j5kG5SG"
   },
   "source": [
    "Converting categorical to nomial for model\n",
    "- Can simply try to do pd.get_dummies\n",
    "- but also maping works well and may be shorted because it just converts it instead of making a new column with get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-flvpwouG-JE"
   },
   "outputs": [],
   "source": [
    "combined['Sex'] = combined['Sex'].map({'male':1, 'female':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugKhMK0svXSk"
   },
   "source": [
    "Correlations and assumptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bclt_idSvVVV"
   },
   "outputs": [],
   "source": [
    "# Stat breakdown \n",
    "    - .describe()\n",
    "    - .describe(include = ['O']) # for cateogrical features \n",
    "    \n",
    "# Correlations / Correlations with different variables in each feature / Trend \n",
    "    - train[['Survived','Sex']][train['Age'] < 16].groupby(['Sex'], as_index = False).sum().sort_values(by = 'Sex', ascending = False) # Allows for a table breakdown of different features \n",
    "      # Survival and Sex can be changed \n",
    "      # To subset the data even further an additional clause can be done with train['Age'] < 16 \n",
    "    - pd.crosstab(train['Survived'][train['Age'] < 16][train['Sex'] == 'male'], columns = 'Survived') # Use when you want a simple clear breakdown of a single feature \n",
    "      #  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltyh6EP3O-db"
   },
   "source": [
    "Vizualizaitons: \n",
    "-  using more on sns \n",
    " https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html\n",
    "- Facet grid is great for breaking it down by a category \n",
    "    -  also helps with figuring out if certain aspects of the continous variable differs \n",
    "\n",
    "You are able to set hue to have a third variable for the graphs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7zEuKJmOlj8"
   },
   "outputs": [],
   "source": [
    "# visualizatins towards some features \n",
    "# Correlations with continous data to continuous data \n",
    "f = sns.FacetGrid(xxxxxx, col= 'yyyy', row = 'zzzzz', hue = 'ggg')\n",
    "f.map(plt.hist, 'iiii', alpha = .5, bins = 20)\n",
    "\n",
    "# or f.map(sns.distplot, 'Age', bins = 10, kde = False, hist_kws=dict(alpha=0.7))\n",
    "f.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3xko6WmWMss"
   },
   "outputs": [],
   "source": [
    "# between categorical to categorical \n",
    "h = sns.FacetGrid(train, row = 'Embarked')\n",
    "h.map(sns.pointplot, 'Pclass', 'Survived', 'Sex')\n",
    "f.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mX0z6RlOYHFt"
   },
   "outputs": [],
   "source": [
    "# between categorical to continuous \n",
    "h = sns.FacetGrid(train, row = 'Embarked', col = 'Survived')\n",
    "h.map(sns.barplot, 'Sex','Fare')\n",
    "h.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcbAmzXCuDCD"
   },
   "outputs": [],
   "source": [
    "# makes a tier level of graphs based on a target feature and some set of columns  \n",
    "nr_rows = 2\n",
    "nr_cols = 3\n",
    "\n",
    "fig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*3.5,nr_rows*3))\n",
    "\n",
    "for r in range(0,nr_rows):\n",
    "    for c in range(0,nr_cols):  \n",
    "        \n",
    "        i = r*nr_cols+c       \n",
    "        ax = axs[r][c]\n",
    "        sns.countplot(df_train[cols[i]], hue=df_train[\"Survived\"], ax=ax)\n",
    "        ax.set_title(cols[i], fontsize=14, fontweight='bold')\n",
    "        ax.legend(title=\"survived\", loc='upper center') \n",
    "        \n",
    "plt.tight_layout()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvqhqMEKZyXJ"
   },
   "source": [
    "Extracting out text from a string using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAKkkJGBZ4Jw"
   },
   "outputs": [],
   "source": [
    "# makes a column that usings regex to extract the prefix from after the column and the first name \n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)\n",
    "    \n",
    "#makes a table from this \n",
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOzn9Flucd_o"
   },
   "source": [
    "Converting Cateogrical features to nomial or ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUILx6HLcdGr"
   },
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "train_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkmAzHK8eoCI"
   },
   "outputs": [],
   "source": [
    "# Filling in empty Age  Go back to understand \n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHksP8eYc86u"
   },
   "source": [
    "Filling in the NA does involves some thought in that it can be tackled in different ways \n",
    "1. Random number - a lot of noise \n",
    "2. based on medium values based off of correlated featurese \n",
    "3. combination of the two but still leads to noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKh2ERAadXeQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMJ6N9t8XF9a"
   },
   "outputs": [],
   "source": [
    "#Create a forloop to check all columns \n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "print(column)\n",
    "print(missing_data[column].value_counts())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrGzIETnXaQy"
   },
   "outputs": [],
   "source": [
    "#delete NA's\n",
    "\n",
    "df.dropna(....., axis = 0, inplace = True )\n",
    "\n",
    "df[\"\"].replace(np.nan, \"mean\", inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gkGojVuTkMO"
   },
   "source": [
    "**Pre-preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc7athEBNzxf"
   },
   "source": [
    "Light understanding of the data:\n",
    "- df.describe()\n",
    "- df.head()\n",
    "- df.tail()\n",
    "- df.dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RN7HC6jXQK0c"
   },
   "source": [
    "Data types \n",
    "- converting\n",
    "df[].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEg8i1oCQWws"
   },
   "source": [
    "Data Normalization\n",
    "- Normalizing so that the variables have a range of values that are consistent \n",
    "- We normalize because if one variable is a larger range than the other then that variable will naturally have a higher weight on the result \n",
    "Types of normalization\n",
    "- Simple feature scaling \n",
    "- Min-max \n",
    "- Z-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvGJVibLThTt"
   },
   "source": [
    "Categorical to Numerical\n",
    "- One shot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bvy4oaHUYEJb"
   },
   "source": [
    "**ETA**\n",
    "\n",
    "Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbcoMr2NajZ3"
   },
   "outputs": [],
   "source": [
    "sns.regplot(x='', y'',data= '')\n",
    "Plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZBB8Lh4cl-d"
   },
   "source": [
    "Pearson correlation, p value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7N7s2G8Gct4G"
   },
   "outputs": [],
   "source": [
    "Pearson_coef, p_value = stats.personr[[\"\"], df[\"\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjIxcb68c4mJ"
   },
   "source": [
    "Analysis of Variance ( ANOVA)\n",
    "\n",
    "finding correlation between different groups of categorical variables \n",
    "\n",
    "F test score: variation between sample group means divided by variation within sample group\n",
    "p value: confidence degree\n",
    "\n",
    "in the stats package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTt0mRuQijVF"
   },
   "source": [
    "Modeling \n",
    "\n",
    "Cross validation:\n",
    "- for accuracy and precision \n",
    "\n",
    "Over fitting \n",
    "\n",
    "Under fitting \n",
    "\n",
    "Model Selection "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Analysis",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
